#!/usr/bin/env cached-nix-shell
#!nix-shell -i bash
#!nix-shell -p curl
#!nix-shell -p gallery-dl

shopt -s extglob

ALWAYS_RENAME=(
	'?'
	'??'
	'???'
	'????'
	'?????'
	'unknown*'
)

md5() {
	md5sum "$1" | cut -c-32
}
sha256() {
	sha256sum "$1" | cut -c-64
}

download_generic() {
	# Try alternative urls.
	urls=(
		# Strip query parameters in case they lower the resolution.
		"$(echo "$url" | sed 's/width=[[:digit:]]\+[?&]\?//g; s/height=[[:digit:]]\+[?&]\?//g; s/?$//')"
		"${url%%\?*}"
		# The original url.
		"$url"
	)
	best=('' -1)
	while [ -z "$tmp" ] && read -r url; do
		printf 'Checking url %q.\n' "$url"

		# Get the content-type and size.
		output="$(curl --head --location --silent --show-error "$url")"
		type="$(echo "$output" | grep -iE '^content-type:' | cut -d: -f2- | tr -d '[[:space:]]' | tail -n1)"
		size="$(echo "$output" | grep -iE '^content-length:' | cut -d: -f2- | tr -d '[[:space:]]' | tail -n1)"
		location="$(echo "$output" | grep -iE '^location:' | cut -d: -f2- | tr -d '[[:space:]]' | tail -n1)"
		if [ -n "$location" ]; then
			url="$location"
		fi

		# Make sure the content type is an image or video.
		printf '  Found %q with size %s.' "$type" "$size"
		case "$type" in
			video/*) echo ;;
			image/*) echo ;;

			*)
				echo " This is not an image or video, skipping."
				continue
			;;
		esac

		# Check whether the size is larger than any other attempted urls.
		if [ "$size" -gt "${best[1]}" ]; then
			echo "  This is the best option thus far."
			best=("$url" "$size")
		else
			echo "  This is not better than previous options, skipping."
		fi
	done < <(printf '%s\n' "${urls[@]}" | sort -u)
	url="${best[0]}"
	if [ -z "$url" ]; then
		echo >&2 "URL did not refer to an image or video."
		exit 1
	fi
	echo "Best option is $url."

	# Download the file and grab the resulting filename.
	tmp="$(wget --directory-prefix=/tmp "$url" --output-file=- --no-verbose | grep -E -- '-> "/tmp' | sed 's!^.* -> "\(/tmp/.*\)" \[1]$!\1!')"
	if [ -z "$tmp" ]; then
		echo >&2 "Unable to get filename of downloaded file."
		exit 1
	fi

	# Get the filename.
	fn="$(basename "$tmp")"
	fn="${fn%%.*([0-9])}"
	fn="${fn%%\?*}"

	files=(["$fn"]="$tmp")
}

download_nitter() {
	case "$url" in
		'https://twitter.com/'*) url_path="${url#https://twitter.com/}" ;;
		'https://mobile.twitter.com/'*) url_path="${url#https://mobile.twitter.com/}" ;;
		'https://vxtwitter.com/'*) url_path="${url#https://vxtwitter.com/}" ;;
		*) return 1 ;;
	esac

	echo "Detected twitter URL, rewriting to nitter."
	for host in 'nitter.net' 'nitter.inpt.fr' 'twitter.censors.us/'; do
		url="nitter:https://$host/$url_path"
		download_gallery_dl
		if [ "${#files[@]}" -gt 0 ]; then
			return 0
		fi
	done
	echo "Failed to download using gallery_dl + nitter."
	return 1
}

download_gallery_dl() {
	# Download using gallery-dl.
	mapfile -t paths < <(gallery-dl "$url" -D /tmp 2> /dev/null) || return 1

	for path in "${paths[@]}"; do
		files["$(basename "$path")"]="${path#\# }"
	done
}


url="$1"
dir="${2%%/}"

printf 'url=%q\n' "$url"
printf 'dir=%q\n' "$dir"
echo

if [ -z "$url" ] || [ -z "$dir" ]; then
	echo >&2 "Usage: $0 url dir"
	exit 1
fi
if [ ! -d "$dir" ]; then
	echo >&2 "'$dir' is not a directory."
	exit 1
fi

# Download the files.
declare -A files
orig_url="$url"
for downloader in nitter gallery_dl generic; do
	echo "Trying $downloader downloader" 
	url="$orig_url"
	"download_$downloader" && [ "${#files[@]}" -gt 0 ] && break
done
if [ "${#files[@]}" -eq 0 ]; then
	echo >&2 "No files downloaded."
	exit 1
fi

for fn in "${!files[@]}"; do
	ext="${fn##*.}"
	basename="${fn%.$ext}"

	tmp="${files["$fn"]}"
	md5new="$(md5 "$tmp")"

	echo
	echo "Processing '$tmp'."

	try_name() {
		echo "Trying to move to '$1'."
		if [ ! -f "$1" ]; then
			mv -n "$tmp" "$1"
			notify-new-file "$1" "Downloaded to $1" &
			echo "Move successful."
			return 0
		elif [ "$(md5 "$1")" = "$md5new" ] && [ "$(sha256 "$1")" = "$(sha256 "$tmp")" ]; then
			rm "$tmp"
			notify-new-file "$1" "File already exists at $1" &
			echo "Files are identical, removing downloaded file."
			return 0
		fi
		return 1
	}

	# Try the original filename, unless it's on the blacklist.
	try_fn=1
	for always_rename in "${ALWAYS_RENAME[@]}"; do
		if [[ "$basename" =~ $always_rename ]]; then
			try_fn=0
			break
		fi
	done
	if [ "$try_fn" -eq 1 ]; then
		try_name "$dir/$fn" && continue
	fi

	# Try the md5sum as filename.
	try_name "$dir/$md5new.$ext" && continue

	# This realy only happens if we already have a file with the same md5 sum, but a different sha256 sum. This is very unlikely, but it's also easy enough to handle, so might as well.
	if [ -f "$tmp" ]; then
		while true; do
			target="$dir/$RANDOM.$ext"
			[ -f "$target" ] && continue
		done
		try_name="$target"
	fi
done
